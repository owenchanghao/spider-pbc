{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Universal Variables Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "\n",
    "from datetime import datetime, date\n",
    "from urllib import request, parse\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "import re\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "### INPUT HERE!\n",
    "year = '2021'\n",
    "month = '12'\n",
    "\n",
    "### AUTO JUDGE DAY\n",
    "if int(month) in {1,3,5,7,8,10,12}:\n",
    "    day = '31'\n",
    "elif int(month) in {4,6,9,11}:\n",
    "    day = '30'\n",
    "else:\n",
    "    if (year % 4) == 0 and (year % 100) != 0 or (year % 400) == 0:\n",
    "        day = '29'\n",
    "    else:\n",
    "        day = '28'\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regional Branches (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html\n",
      "['2021-12-24', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html']\n",
      "['2021-12-13', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html']\n",
      "['2021-12-09', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shanghai'\n",
    "\n",
    "def shSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shanghai.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shanghai.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "shSpider('http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Tianjin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'tianjin'\n",
    "\n",
    "def tjSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://tianjin.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://tianjin.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "tjSpider('http://tianjin.pbc.gov.cn/fzhtianjin/113682/113700/113707/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Shenyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html\n",
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html\n",
      "['2021-12-20', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html']\n",
      "['2021-12-06', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shenyang'\n",
    "\n",
    "def sySpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shenyang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shenyang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "sySpider('http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/index.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Nanjing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html\n",
      "['2021-12-31', 'http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'nanjing'\n",
    "\n",
    "def njSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://nanjing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://nanjing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "njSpider('http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Jinan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4418095/index.html\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html']\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html']\n",
      "['2021-12-22', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html']\n",
      "['2021-12-21', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html']\n",
      "['2021-12-20', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html']\n",
      "['2021-12-17', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4418095/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'jinan'\n",
    "\n",
    "def jnSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://jinan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://jinan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "jnSpider('http://jinan.pbc.gov.cn/jinan/120967/120985/120994/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Wuhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html']\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html']\n",
      "['2021-12-24', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html']\n",
      "['2021-12-21', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html']\n",
      "['2021-12-03', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'wuhan'\n",
    "\n",
    "def whSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://wuhan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://wuhan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "whSpider('http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Guangzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html']\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html']\n",
      "['2021-12-24', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html']\n",
      "['2021-12-23', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'guangzhou'\n",
    "\n",
    "def gzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://guangzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://guangzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "gzSpider('http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Chengdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435747/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435742/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427688/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427204/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4421647/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4429963/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413845/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413840/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4404467/index.html\n",
      "['2021-12-30', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435747/index.html']\n",
      "['2021-12-30', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435742/index.html']\n",
      "['2021-12-22', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427688/index.html']\n",
      "['2021-12-22', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427204/index.html']\n",
      "['2021-12-20', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4421647/index.html']\n",
      "['2021-12-20', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4429963/index.html']\n",
      "['2021-12-13', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413845/index.html']\n",
      "['2021-12-13', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413840/index.html']\n",
      "['2021-12-01', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4404467/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'chengdu'\n",
    "\n",
    "def cdSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "   \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT, Chengdu's width is 66\n",
    "            for inner in temp.find_all(\"td\", width=\"66\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://chengdu.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://chengdu.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "cdSpider('http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Xi'an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'xian'\n",
    "\n",
    "def xaSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://xian.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://xian.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "xaSpider('http://xian.pbc.gov.cn/xian/129428/129449/129458/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Direct Operational Dept. (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Beijing\n",
    "\n",
    "Beijing's PBC official website has been changed to width 140 instead of an usual 100. After a series of tests (prints), I spotted this issue and changed 100 to 140 to fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4422548/index.html\n",
      "http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4406730/index.html\n",
      "['2021-12-20', 'http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4422548/index.html']\n",
      "['2021-12-03', 'http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4406730/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'beijing'\n",
    "\n",
    "def bjSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(3)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    prevd = 0\n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT, note Beijing has width 140!\n",
    "            for inner in temp.find_all(\"td\", width=\"140\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://beijing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://beijing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "bjSpider('http://beijing.pbc.gov.cn/beijing/132030/132052/132059/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Chongqing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nname = \\'chongqing\\'\\n\\ndef cqSpider(link):\\n    driver = webdriver.Chrome()\\n    time.sleep(3)\\n    driver.get(link)\\n    req = driver.page_source\\n    # print(req)\\n    soup = BeautifulSoup(req, \\'lxml\\')\\n    # print(soup.prettify())\\n    fram = soup.find(\"div\", id = \"8000\")\\n    # print(fram.prettify())\\n    mylist = []\\n    finallist = []\\n    \\n    count = 0\\n    datelist = []\\n    linklist = []\\n    for item in fram.find_all(\"table\"):\\n        print(item)\\n        for temp in item.find_all(\"td\", limit=1):\\n            ### FILTER ALL TIME OUT\\n            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\\n                d = datetime.strptime(inner.text, \\'%Y-%m-%d\\')\\n                # print(d)\\n                if ((d >= datetime(int(year), int(month), 1)) \\n                    & (d <= datetime(int(year), int(month), int(day)))):\\n                    #print(d)\\n                    datelist.append(d)\\n                    count += 1\\n                else:\\n                    pass\\n            if (count == 0):\\n                print(\"Not a single fine found...\")\\n                break\\n            l = temp.select(\\'a[href]\\', limit=count)\\n            for k in range(0,len(l)):\\n                print(\"http://chongqing.pbc.gov.cn\" + (l[k][\\'href\\']))\\n                w = \"http://chongqing.pbc.gov.cn\" + (l[k][\\'href\\'])\\n                linklist.append(w)\\n    \\n    txt = \\'{y}-{m}-{n}.csv\\' # put city at the end is better...?\\n    f = open(txt.format(n = name, y = year, m = month), \\'w\\')\\n    writer = csv.writer(f)\\n    writer.writerow([\\'发布日期\\', \\'罚单链接\\'])\\n    \\n    for i in range(0, count):\\n        dlist = []\\n        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\\n        dlist.append(linklist[i])\\n        print(dlist)\\n        writer.writerow(dlist)\\n    \\n    f.close()\\n\\n### INPUT OFFICIAL WEBSITE INSIDE                           \\ncqSpider(\\'http://chongqing.pbc.gov.cn/chongqing/107680/107897/107909/index.html\\')\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need further refinement.\n",
    "'''\n",
    "\n",
    "name = 'chongqing'\n",
    "\n",
    "def cqSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(3)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"div\", id = \"8000\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\"):\n",
    "        print(item)\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                # print(d)\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://chongqing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://chongqing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "cqSpider('http://chongqing.pbc.gov.cn/chongqing/107680/107897/107909/index.html')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Capital Branches (20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Non-capital Branches (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Shenzhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4433135/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4421186/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4413157/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4407602/index.html\n",
      "['2021-12-27', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4433135/index.html']\n",
      "['2021-12-20', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4421186/index.html']\n",
      "['2021-12-13', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4413157/index.html']\n",
      "['2021-12-06', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4407602/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shenzhen'\n",
    "\n",
    "def szSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shenzhen.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shenzhen.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "szSpider('http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Dalian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Qingdao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Ningbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Xiamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
