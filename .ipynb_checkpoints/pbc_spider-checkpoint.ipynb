{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Universal Variables Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "\n",
    "from datetime import datetime, date\n",
    "from urllib import request, parse\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "import re\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "### INPUT HERE!\n",
    "year = '2021'\n",
    "month = '12'\n",
    "\n",
    "### AUTO JUDGE DAY\n",
    "if int(month) in {1,3,5,7,8,10,12}:\n",
    "    day = '31'\n",
    "elif int(month) in {4,6,9,11}:\n",
    "    day = '30'\n",
    "else:\n",
    "    if (year % 4) == 0 and (year % 100) != 0 or (year % 400) == 0:\n",
    "        day = '29'\n",
    "    else:\n",
    "        day = '28'\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regional Branches (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html\n",
      "['2021-12-24', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html']\n",
      "['2021-12-13', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html']\n",
      "['2021-12-09', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shanghai'\n",
    "\n",
    "def shSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shanghai.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shanghai.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "shSpider('http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Tianjin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'tianjin'\n",
    "\n",
    "def tjSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://tianjin.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://tianjin.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "tjSpider('http://tianjin.pbc.gov.cn/fzhtianjin/113682/113700/113707/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Shenyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html\n",
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html\n",
      "['2021-12-20', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html']\n",
      "['2021-12-06', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shenyang'\n",
    "\n",
    "def sySpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shenyang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shenyang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "sySpider('http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/index.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Nanjing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html\n",
      "['2021-12-31', 'http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'nanjing'\n",
    "\n",
    "def njSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://nanjing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://nanjing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "njSpider('http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Jinan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4418095/index.html\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html']\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html']\n",
      "['2021-12-22', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html']\n",
      "['2021-12-21', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html']\n",
      "['2021-12-20', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html']\n",
      "['2021-12-17', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4418095/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'jinan'\n",
    "\n",
    "def jnSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://jinan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://jinan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "jnSpider('http://jinan.pbc.gov.cn/jinan/120967/120985/120994/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Wuhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html']\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html']\n",
      "['2021-12-24', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html']\n",
      "['2021-12-21', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html']\n",
      "['2021-12-03', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'wuhan'\n",
    "\n",
    "def whSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://wuhan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://wuhan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "whSpider('http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Guangzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html']\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html']\n",
      "['2021-12-24', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html']\n",
      "['2021-12-23', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'guangzhou'\n",
    "\n",
    "def gzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://guangzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://guangzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "gzSpider('http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Chengdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435747/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435742/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427688/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427204/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4421647/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4429963/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413845/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413840/index.html\n",
      "http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4404467/index.html\n",
      "['2021-12-30', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435747/index.html']\n",
      "['2021-12-30', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4435742/index.html']\n",
      "['2021-12-22', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427688/index.html']\n",
      "['2021-12-22', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4427204/index.html']\n",
      "['2021-12-20', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4421647/index.html']\n",
      "['2021-12-20', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4429963/index.html']\n",
      "['2021-12-13', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413845/index.html']\n",
      "['2021-12-13', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4413840/index.html']\n",
      "['2021-12-01', 'http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/4404467/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'chengdu'\n",
    "\n",
    "def cdSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "   \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT, Chengdu's width is 66\n",
    "            for inner in temp.find_all(\"td\", width=\"66\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://chengdu.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://chengdu.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "cdSpider('http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Xi'an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'xian'\n",
    "\n",
    "def xaSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://xian.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://xian.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "xaSpider('http://xian.pbc.gov.cn/xian/129428/129449/129458/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Direct Operational Dept. (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Beijing\n",
    "\n",
    "Beijing's PBC official website has been changed to width 140 instead of an usual 100. After a series of tests (prints), I spotted this issue and changed 100 to 140 to fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4422548/index.html\n",
      "http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4406730/index.html\n",
      "['2021-12-20', 'http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4422548/index.html']\n",
      "['2021-12-03', 'http://beijing.pbc.gov.cn/beijing/132030/132052/132059/4406730/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'beijing'\n",
    "\n",
    "def bjSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(3)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    prevd = 0\n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT, note Beijing has width 140!\n",
    "            for inner in temp.find_all(\"td\", width=\"140\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://beijing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://beijing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "bjSpider('http://beijing.pbc.gov.cn/beijing/132030/132052/132059/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Chongqing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nname = \\'chongqing\\'\\n\\ndef cqSpider(link):\\n    driver = webdriver.Chrome()\\n    time.sleep(3)\\n    driver.get(link)\\n    req = driver.page_source\\n    # print(req)\\n    soup = BeautifulSoup(req, \\'lxml\\')\\n    # print(soup.prettify())\\n    fram = soup.find(\"div\", id = \"8000\")\\n    # print(fram.prettify())\\n    mylist = []\\n    finallist = []\\n    \\n    count = 0\\n    datelist = []\\n    linklist = []\\n    for item in fram.find_all(\"table\"):\\n        print(item)\\n        for temp in item.find_all(\"td\", limit=1):\\n            ### FILTER ALL TIME OUT\\n            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\\n                d = datetime.strptime(inner.text, \\'%Y-%m-%d\\')\\n                # print(d)\\n                if ((d >= datetime(int(year), int(month), 1)) \\n                    & (d <= datetime(int(year), int(month), int(day)))):\\n                    #print(d)\\n                    datelist.append(d)\\n                    count += 1\\n                else:\\n                    pass\\n            if (count == 0):\\n                print(\"Not a single fine found...\")\\n                break\\n            l = temp.select(\\'a[href]\\', limit=count)\\n            for k in range(0,len(l)):\\n                print(\"http://chongqing.pbc.gov.cn\" + (l[k][\\'href\\']))\\n                w = \"http://chongqing.pbc.gov.cn\" + (l[k][\\'href\\'])\\n                linklist.append(w)\\n    \\n    txt = \\'{y}-{m}-{n}.csv\\' # put city at the end is better...?\\n    f = open(txt.format(n = name, y = year, m = month), \\'w\\')\\n    writer = csv.writer(f)\\n    writer.writerow([\\'发布日期\\', \\'罚单链接\\'])\\n    \\n    for i in range(0, count):\\n        dlist = []\\n        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\\n        dlist.append(linklist[i])\\n        print(dlist)\\n        writer.writerow(dlist)\\n    \\n    f.close()\\n\\n### INPUT OFFICIAL WEBSITE INSIDE                           \\ncqSpider(\\'http://chongqing.pbc.gov.cn/chongqing/107680/107897/107909/index.html\\')\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need further refinement.\n",
    "'''\n",
    "\n",
    "name = 'chongqing'\n",
    "\n",
    "def cqSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(3)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"div\", id = \"8000\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\"):\n",
    "        print(item)\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                # print(d)\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://chongqing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://chongqing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "cqSpider('http://chongqing.pbc.gov.cn/chongqing/107680/107897/107909/index.html')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Capital Branches (20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Shijiazhuang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'shijiazhuang'\n",
    "\n",
    "def sjzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shijiazhuang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shijiazhuang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "sjzSpider('http://shijiazhuang.pbc.gov.cn/shijiazhuang/131442/131463/131472/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Taiyuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436929/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436924/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436386/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4430681/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4429904/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428946/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428767/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428762/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4427862/index.html\n",
      "http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4426001/index.html\n",
      "['2021-12-31', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436929/index.html']\n",
      "['2021-12-31', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436924/index.html']\n",
      "['2021-12-31', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4436386/index.html']\n",
      "['2021-12-27', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4430681/index.html']\n",
      "['2021-12-24', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4429904/index.html']\n",
      "['2021-12-23', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428946/index.html']\n",
      "['2021-12-23', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428767/index.html']\n",
      "['2021-12-23', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4428762/index.html']\n",
      "['2021-12-23', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4427862/index.html']\n",
      "['2021-12-22', 'http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/4426001/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'taiyuan'\n",
    "\n",
    "def tySpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://taiyuan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://taiyuan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "tySpider('http://taiyuan.pbc.gov.cn/taiyuan/133960/133981/133988/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Huhhot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4437062/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4436575/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4436067/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4435995/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4435990/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4427891/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4418838/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4415482/index.html\n",
      "http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4414667/index.html\n",
      "['2021-12-31', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4437062/index.html']\n",
      "['2021-12-31', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4436575/index.html']\n",
      "['2021-12-30', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4436067/index.html']\n",
      "['2021-12-30', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4435995/index.html']\n",
      "['2021-12-30', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4435990/index.html']\n",
      "['2021-12-23', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4427891/index.html']\n",
      "['2021-12-17', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4418838/index.html']\n",
      "['2021-12-15', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4415482/index.html']\n",
      "['2021-12-14', 'http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/4414667/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'huhhot'\n",
    "\n",
    "def hhSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://huhehaote.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://huhehaote.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "hhSpider('http://huhehaote.pbc.gov.cn/huhehaote/129797/129815/129822/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Changchun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4434365/index.html\n",
      "http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4432030/index.html\n",
      "http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4428901/index.html\n",
      "http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4427563/index.html\n",
      "['2021-12-28', 'http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4434365/index.html']\n",
      "['2021-12-27', 'http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4432030/index.html']\n",
      "['2021-12-23', 'http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4428901/index.html']\n",
      "['2021-12-22', 'http://changchun.pbc.gov.cn/changchun/124680/124698/124705/4427563/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'changchun'\n",
    "\n",
    "def ccSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://changchun.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://changchun.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "ccSpider('http://changchun.pbc.gov.cn/changchun/124680/124698/124705/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Harbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4430141/index.html\n",
      "http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4426365/index.html\n",
      "http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4405671/index.html\n",
      "['2021-12-24', 'http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4430141/index.html']\n",
      "['2021-12-22', 'http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4426365/index.html']\n",
      "['2021-12-03', 'http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/4405671/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'harbin'\n",
    "\n",
    "def hbSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://haerbin.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://haerbin.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "hbSpider('http://haerbin.pbc.gov.cn/haerbin/112693/112776/112783/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Hangzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://hangzhou.pbc.gov.cn/hangzhou/125268/125286/125293/4436718/index.html\n",
      "['2021-12-27', 'http://hangzhou.pbc.gov.cn/hangzhou/125268/125286/125293/4436718/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'hangzhou'\n",
    "\n",
    "def hzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://hangzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://hangzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "hzSpider('http://hangzhou.pbc.gov.cn/hangzhou/125268/125286/125293/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Fuzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://fuzhou.pbc.gov.cn/fuzhou/126805/126823/126830/4439124/index.html\n",
      "http://fuzhou.pbc.gov.cn/fuzhou/126805/126823/126830/4404553/index.html\n",
      "['2021-12-31', 'http://fuzhou.pbc.gov.cn/fuzhou/126805/126823/126830/4439124/index.html']\n",
      "['2021-12-01', 'http://fuzhou.pbc.gov.cn/fuzhou/126805/126823/126830/4404553/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'fuzhou'\n",
    "\n",
    "def fzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://fuzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://fuzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "fzSpider('http://fuzhou.pbc.gov.cn/fuzhou/126805/126823/126830/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.8 Hefei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4436520/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4435822/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4431947/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4429013/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4424098/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4413925/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4410040/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4407712/index.html\n",
      "http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4404728/index.html\n",
      "['2021-12-31', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4436520/index.html']\n",
      "['2021-12-30', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4435822/index.html']\n",
      "['2021-12-27', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4431947/index.html']\n",
      "['2021-12-23', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4429013/index.html']\n",
      "['2021-12-21', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4424098/index.html']\n",
      "['2021-12-14', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4413925/index.html']\n",
      "['2021-12-08', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4410040/index.html']\n",
      "['2021-12-06', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4407712/index.html']\n",
      "['2021-12-01', 'http://hefei.pbc.gov.cn/hefei/122364/122382/122389/4404728/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'hefei'\n",
    "\n",
    "def hfSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://hefei.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://hefei.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "hfSpider('http://hefei.pbc.gov.cn/hefei/122364/122382/122389/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.9 Zhengzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4435280/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4433764/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4430134/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4430124/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4427827/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4422118/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4417920/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4415830/index.html\n",
      "http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4410786/index.html\n",
      "['2021-12-29', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4435280/index.html']\n",
      "['2021-12-28', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4433764/index.html']\n",
      "['2021-12-24', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4430134/index.html']\n",
      "['2021-12-24', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4430124/index.html']\n",
      "['2021-12-23', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4427827/index.html']\n",
      "['2021-12-20', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4422118/index.html']\n",
      "['2021-12-17', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4417920/index.html']\n",
      "['2021-12-15', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4415830/index.html']\n",
      "['2021-12-09', 'http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/4410786/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'zhengzhou'\n",
    "\n",
    "def zzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://zhengzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://zhengzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "zzSpider('http://zhengzhou.pbc.gov.cn/zhengzhou/124182/124200/124207/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.10 Changsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4434108/index.html\n",
      "http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4417027/index.html\n",
      "http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4412178/index.html\n",
      "['2021-12-31', 'http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4434108/index.html']\n",
      "['2021-12-16', 'http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4417027/index.html']\n",
      "['2021-12-09', 'http://changsha.pbc.gov.cn/changsha/130011/130029/130036/4412178/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'changsha'\n",
    "\n",
    "def csSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://changsha.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://changsha.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "csSpider('http://changsha.pbc.gov.cn/changsha/130011/130029/130036/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.11 Nanchang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4430535/index.html\n",
      "http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4418984/index.html\n",
      "http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4420739/index.html\n",
      "http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4413886/index.html\n",
      "['2021-12-24', 'http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4430535/index.html']\n",
      "['2021-12-17', 'http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4418984/index.html']\n",
      "['2021-12-15', 'http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4420739/index.html']\n",
      "['2021-12-14', 'http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/4413886/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'nanchang'\n",
    "\n",
    "def ncSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://nanchang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://nanchang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "ncSpider('http://nanchang.pbc.gov.cn/nanchang/132372/132390/132397/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.12 Nanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4437162/index.html\n",
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4435506/index.html\n",
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4435501/index.html\n",
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4432873/index.html\n",
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4430198/index.html\n",
      "http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4430193/index.html\n",
      "['2021-12-31', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4437162/index.html']\n",
      "['2021-12-29', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4435506/index.html']\n",
      "['2021-12-29', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4435501/index.html']\n",
      "['2021-12-27', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4432873/index.html']\n",
      "['2021-12-24', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4430198/index.html']\n",
      "['2021-12-24', 'http://nanning.pbc.gov.cn/nanning/133346/133364/133371/4430193/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'nanning'\n",
    "\n",
    "def nnnSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://nanning.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://nanning.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "nnnSpider('http://nanning.pbc.gov.cn/nanning/133346/133364/133371/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.13 Haikou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://haikou.pbc.gov.cn/haikou/132982/133000/133007/4430222/index.html\n",
      "['2021-12-24', 'http://haikou.pbc.gov.cn/haikou/132982/133000/133007/4430222/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'haikou'\n",
    "\n",
    "def hkSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://haikou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://haikou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "hkSpider('http://haikou.pbc.gov.cn/haikou/132982/133000/133007/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.14 Kunming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437535/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437294/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437078/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4436000/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4429408/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4427919/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4436288/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4424836/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4410340/index.html\n",
      "http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4409351/index.html\n",
      "['2021-12-31', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437535/index.html']\n",
      "['2021-12-31', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437294/index.html']\n",
      "['2021-12-31', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4437078/index.html']\n",
      "['2021-12-30', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4436000/index.html']\n",
      "['2021-12-24', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4429408/index.html']\n",
      "['2021-12-23', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4427919/index.html']\n",
      "['2021-12-22', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4436288/index.html']\n",
      "['2021-12-21', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4424836/index.html']\n",
      "['2021-12-09', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4410340/index.html']\n",
      "['2021-12-07', 'http://kunming.pbc.gov.cn/kunming/133736/133760/133767/4409351/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'kunming'\n",
    "\n",
    "def kmSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://kunming.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://kunming.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "kmSpider('http://kunming.pbc.gov.cn/kunming/133736/133760/133767/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.15 Guiyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://guiyang.pbc.gov.cn/guiyang/113288/113306/113313/4431565/index.html\n",
      "['2021-12-27', 'http://guiyang.pbc.gov.cn/guiyang/113288/113306/113313/4431565/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'guiyang'\n",
    "\n",
    "def gySpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://guiyang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://guiyang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "gySpider('http://guiyang.pbc.gov.cn/guiyang/113288/113306/113313/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.16 Lhasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lasa.pbc.gov.cn/lasa/120480/120504/120511/4434713/index.html\n",
      "http://lasa.pbc.gov.cn/lasa/120480/120504/120511/4438640/index.html\n",
      "['2021-12-24', 'http://lasa.pbc.gov.cn/lasa/120480/120504/120511/4434713/index.html']\n",
      "['2021-12-24', 'http://lasa.pbc.gov.cn/lasa/120480/120504/120511/4438640/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'lhasa'\n",
    "\n",
    "def lasaSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://lasa.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://lasa.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "lasaSpider('http://lasa.pbc.gov.cn/lasa/120480/120504/120511/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.17 Lanzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4430150/index.html\n",
      "http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4428710/index.html\n",
      "http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4412124/index.html\n",
      "http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4406624/index.html\n",
      "['2021-12-24', 'http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4430150/index.html']\n",
      "['2021-12-23', 'http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4428710/index.html']\n",
      "['2021-12-10', 'http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4412124/index.html']\n",
      "['2021-12-03', 'http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/4406624/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'lanzhou'\n",
    "\n",
    "def lzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://lanzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://lanzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "lzSpider('http://lanzhou.pbc.gov.cn/lanzhou/117067/117091/117098/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.18 Xining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://xining.pbc.gov.cn/xining/118239/118263/118270/4437115/index.html\n",
      "http://xining.pbc.gov.cn/xining/118239/118263/118270/4407328/index.html\n",
      "['2021-12-31', 'http://xining.pbc.gov.cn/xining/118239/118263/118270/4437115/index.html']\n",
      "['2021-12-06', 'http://xining.pbc.gov.cn/xining/118239/118263/118270/4407328/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'xining'\n",
    "\n",
    "def xnSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://xining.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://xining.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "xnSpider('http://xining.pbc.gov.cn/xining/118239/118263/118270/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.19 Yinchuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'yinchuan'\n",
    "\n",
    "def ycSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://yinchuan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://yinchuan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "ycSpider('http://yinchuan.pbc.gov.cn/yinchuan/119983/120001/120008/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.20 Urumqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4435526/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428660/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428647/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428007/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428000/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425586/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425581/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425570/index.html\n",
      "http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4418224/index.html\n",
      "['2021-12-29', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4435526/index.html']\n",
      "['2021-12-23', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428660/index.html']\n",
      "['2021-12-23', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428647/index.html']\n",
      "['2021-12-23', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428007/index.html']\n",
      "['2021-12-23', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4428000/index.html']\n",
      "['2021-12-21', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425586/index.html']\n",
      "['2021-12-21', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425581/index.html']\n",
      "['2021-12-21', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4425570/index.html']\n",
      "['2021-12-17', 'http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/4418224/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'urumqi'\n",
    "\n",
    "def urmqSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://wulumuqi.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://wulumuqi.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "urmqSpider('http://wulumuqi.pbc.gov.cn/wulumuqi/121755/121777/121784/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Non-capital Branches (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Shenzhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4433135/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4421186/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4413157/index.html\n",
      "http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4407602/index.html\n",
      "['2021-12-27', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4433135/index.html']\n",
      "['2021-12-20', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4421186/index.html']\n",
      "['2021-12-13', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4413157/index.html']\n",
      "['2021-12-06', 'http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/4407602/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shenzhen'\n",
    "\n",
    "def szSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://shenzhen.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shenzhen.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "szSpider('http://shenzhen.pbc.gov.cn/shenzhen/122811/122833/122840/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Dalian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://dalian.pbc.gov.cn/dalian/123812/123830/123837/4410989/index.html\n",
      "['2021-12-10', 'http://dalian.pbc.gov.cn/dalian/123812/123830/123837/4410989/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'dalian'\n",
    "\n",
    "def dlSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://dalian.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://dalian.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "dlSpider('http://dalian.pbc.gov.cn/dalian/123812/123830/123837/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Qingdao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://qingdao.pbc.gov.cn/qingdao/126166/126184/126191/4412381/index.html\n",
      "['2021-12-11', 'http://qingdao.pbc.gov.cn/qingdao/126166/126184/126191/4412381/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'qingdao'\n",
    "\n",
    "def qdSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://qingdao.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://qingdao.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "qdSpider('http://qingdao.pbc.gov.cn/qingdao/126166/126184/126191/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Ningbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'ningbo'\n",
    "\n",
    "def nbSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://ningbo.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://ningbo.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "nbSpider('http://ningbo.pbc.gov.cn/ningbo/127076/127098/127105/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Xiamen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://xiamen.pbc.gov.cn/xiamen/127703/127721/127728/4436682/index.html\n",
      "['2021-12-31', 'http://xiamen.pbc.gov.cn/xiamen/127703/127721/127728/4436682/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'xiamen'\n",
    "\n",
    "def xmSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    \n",
    "    count = 0\n",
    "    prevd = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                elif (d > datetime(int(year), int(month), int(day))):\n",
    "                    prevd += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count+prevd)\n",
    "            for k in range(0+prevd, len(l)):\n",
    "                print(\"http://xiamen.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://xiamen.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "xmSpider('http://xiamen.pbc.gov.cn/xiamen/127703/127721/127728/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Notice (in Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 地区分行（共9家：上海、天津、沈阳、南京、济南、武汉、广州、成都、西安）\n",
    "2. 营业管理部（共2家：北京、**重庆**）\n",
    "3. 省会支行（共20家）\n",
    "4. 非省会支行（共5家：深圳、大连、宁波、青岛、厦门）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Q&A (in Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该爬虫程序是否违法？\n",
    "- 不违法。所有爬取的罚单信息都是公开透明的，不侵犯国家隐私、不危害国家安全。\n",
    "\n",
    "tbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end of the file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
