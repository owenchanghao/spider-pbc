{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding = utf-8 -*-\n",
    "\n",
    "from datetime import datetime, date\n",
    "from urllib import request, parse\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from fake_useragent import UserAgent\n",
    "import csv\n",
    "import re\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Universal Variables Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "### INPUT HERE!\n",
    "year = '2021'\n",
    "month = '12'\n",
    "\n",
    "### AUTO JUDGE DAY\n",
    "if int(month) in {1,3,5,7,8,10,12}:\n",
    "    day = '31'\n",
    "elif int(month) in {4,6,9,11}:\n",
    "    day = '30'\n",
    "else:\n",
    "    if (year % 4) == 0 and (year % 100) != 0 or (year % 400) == 0:\n",
    "        day = '29'\n",
    "    else:\n",
    "        day = '28'\n",
    "print(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regional Branches (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html\n",
      "http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html\n",
      "['2021-12-24', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4429420/index.html']\n",
      "['2021-12-13', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4412681/index.html']\n",
      "['2021-12-09', 'http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/4410609/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shanghai'\n",
    "\n",
    "def shSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://shanghai.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shanghai.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "shSpider('http://shanghai.pbc.gov.cn/fzhshanghai/113577/114832/114918/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Tianjin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'tianjin'\n",
    "\n",
    "def tjSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://tianjin.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://tianjin.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "tjSpider('http://tianjin.pbc.gov.cn/fzhtianjin/113682/113700/113707/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Shenyang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html\n",
      "http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html\n",
      "['2021-12-20', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4437795/index.html']\n",
      "['2021-12-06', 'http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/4412532/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'shenyang'\n",
    "\n",
    "def sySpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://shenyang.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://shenyang.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "sySpider('http://shenyang.pbc.gov.cn/shenyfh/108074/108127/108208/index.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Nanjing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html\n",
      "['2021-12-31', 'http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/4437230/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'nanjing'\n",
    "\n",
    "def njSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://nanjing.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://nanjing.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better.\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "njSpider('http://nanjing.pbc.gov.cn/nanjing/117542/117560/117567/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Jinan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4438577/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html\n",
      "http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4438577/index.html']\n",
      "['2021-12-31', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436741/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4436712/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431771/index.html']\n",
      "['2021-12-27', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4431386/index.html']\n",
      "['2021-12-22', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4430701/index.html']\n",
      "['2021-12-21', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4427013/index.html']\n",
      "['2021-12-20', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423986/index.html']\n",
      "['2021-12-17', 'http://jinan.pbc.gov.cn/jinan/120967/120985/120994/4423126/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'jinan'\n",
    "\n",
    "def jnSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://jinan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://jinan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "jnSpider('http://jinan.pbc.gov.cn/jinan/120967/120985/120994/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Wuhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html\n",
      "http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433664/index.html']\n",
      "['2021-12-28', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4433622/index.html']\n",
      "['2021-12-24', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4430315/index.html']\n",
      "['2021-12-21', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4424940/index.html']\n",
      "['2021-12-03', 'http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/4406720/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'wuhan'\n",
    "\n",
    "def whSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://wuhan.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://wuhan.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "whSpider('http://wuhan.pbc.gov.cn/wuhan/123472/123493/123502/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Guangzhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html\n",
      "http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433798/index.html']\n",
      "['2021-12-27', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433789/index.html']\n",
      "['2021-12-24', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433778/index.html']\n",
      "['2021-12-23', 'http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/4433773/index.html']\n"
     ]
    }
   ],
   "source": [
    "name = 'guangzhou'\n",
    "\n",
    "def gzSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://guangzhou.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://guangzhou.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "gzSpider('http://guangzhou.pbc.gov.cn/guangzhou/129142/129159/129166/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Chengdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'chengdu'\n",
    "\n",
    "def cdSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://chengdu.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://chengdu.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "cdSpider('http://chengdu.pbc.gov.cn/chengdu/129320/129341/129350/index.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Xi'an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a single fine found...\n"
     ]
    }
   ],
   "source": [
    "name = 'xian'\n",
    "\n",
    "def xaSpider(link):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(1)\n",
    "    driver.get(link)\n",
    "    req = driver.page_source\n",
    "    # print(req)\n",
    "    soup = BeautifulSoup(req, 'lxml')\n",
    "    # print(soup.prettify())\n",
    "    fram = soup.find(\"td\", class_ = \"content_right column\")\n",
    "    # print(fram.prettify())\n",
    "    mylist = []\n",
    "    finallist = []\n",
    "    \n",
    "    count = 0\n",
    "    datelist = []\n",
    "    linklist = []\n",
    "    for item in fram.find_all(\"table\", limit=1):\n",
    "        for temp in item.find_all(\"td\", limit=1):\n",
    "            ### FILTER ALL TIME OUT\n",
    "            for inner in temp.find_all(\"td\", width=\"100\", class_=\"hei12jj\", limit=10):\n",
    "                d = datetime.strptime(inner.text, '%Y-%m-%d')\n",
    "                if ((d >= datetime(int(year), int(month), 1)) \n",
    "                    & (d <= datetime(int(year), int(month), int(day)))):\n",
    "                    #print(d)\n",
    "                    datelist.append(d)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            if (count == 0):\n",
    "                print(\"Not a single fine found...\")\n",
    "                break\n",
    "            l = temp.select('a[href]', limit=count)\n",
    "            for k in range(0,len(l)):\n",
    "                print(\"http://xian.pbc.gov.cn\" + (l[k]['href']))\n",
    "                w = \"http://xian.pbc.gov.cn\" + (l[k]['href'])\n",
    "                linklist.append(w)\n",
    "    \n",
    "    txt = '{y}-{m}-{n}.csv' # put city at the end is better...?\n",
    "    f = open(txt.format(n = name, y = year, m = month), 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['发布日期', '罚单链接'])\n",
    "    \n",
    "    for i in range(0, count):\n",
    "        dlist = []\n",
    "        dlist.append(datelist[i].date().strftime(\"%Y-%m-%d\"))\n",
    "        dlist.append(linklist[i])\n",
    "        print(dlist)\n",
    "        writer.writerow(dlist)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "### INPUT OFFICIAL WEBSITE INSIDE                           \n",
    "xaSpider('http://xian.pbc.gov.cn/xian/129428/129449/129458/index.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
